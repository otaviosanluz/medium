{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Variáveis constantes e quase-constantes\n",
    "Neste artigo, você encontra uma breve explicação sobre feature selection e um tutorial de como lidar com variáveis constantes e quase-constantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um conjunto de dados geralmente começa com um grande número de features (variáveis), porém podemos empregar uma variedade de métodos com o objetivo de determinar quais dessas features são realmente importantes para realizar as previsões. Esse procedimento é conhecido como feature selection ou seleção de variáveis.\n",
    "\n",
    "Feature selection pode ser definido como o processo na qual você seleciona automaticamente ou manualmente aquelas features que mais contribuem para a predição da variável target (variável de previsão). Em outras palavras, é o processo de selecionar um subconjunto de features relevantes do seu conjunto total de dados, com o objetivo de construir um algoritmo de machine learning. As features que são utilizadas para treinar seu modelo de machine learning, posuem uma grande influência no resultado que seu modelo pode alcançar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quais os benefícios de aplicar feature selection? Abaixo indico alguns benefícios, porém existem outros.\n",
    "- Redução do overfitting \n",
    "- Melhora da acurácia\n",
    "- Redução do tempo de treinamento do modelo\n",
    "- Modelos com menor propensão a erros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vários métodos foram desenvolvidos para selecionar aquelas features ideais para a construção de um algoritmo de machine learning. As técnicas utilizadas podem ser divididas em três categorias principais:\n",
    "1. **Filter Methods**: Métodos de seleção que utilizam medidas estatísticas para atribuir um score para cada feature. As features são classificadas pelo score para serem mantidas ou removidas do modelo. Normalmente se usam testes univariados que consideram a independência da feature com a variável alvo.\n",
    "2. **Wrapper Methods** : Métodos de seleção que selecionam um conjunto de features, onde diferentes combinações são preparadas, avaliadas e comparadas. Um modelo preditivo é usado para avaliar a combinação de features a atribuir um score baseado em uma acurácia de modelo. \n",
    "3. **Embedded Methods**: Métodos Embedded aprendem quais features melhor contribuiem para a acurácia do modelo no momento de construção do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste artigo, estarei concentrado nos filter methods, mais precisamente em um método básico e simples, porém bastante eficiente, utilizado para selecionar variáveis constantes e quase-constantes. Esse método baseia-se apenas na variância de cada feature. Sendo as features com variância igual a 0, consideradas como constantes, uma vez que seus valores são o mesmo para todos os registros. Já as features quase-constantes, possuem uma variância muito pequena, ou seja, seu valor é quase sempre o mesmo em todo o dataset, por isso são chamadas de quase-constantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando trabalhamos com um conjunto de dados muito extenso, com muitas features, pode ser complicado e até mesmo inviável determinar quais features possuem valores constantes ou quase-constantes. Dessa forma, é importante que o trabalho seja automatizado, fazendo com que todo o processo ocorra de maneira mais rápida, além de manter a qualidade da análise. Para que isso seja possível, podemos utilizar o método VarianceThreshold pertencente a biblioteca sklearn,da linguagem de programação Python. O método é bastante simples e consiste em atribuir um threshold, ou seja, um limiar, um valor na qual servirá como um filtro, removendo as features que apresentarem limite inferior a variância informada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo o processo será feito através da linguagem Python e o conjunto de dados utilizado pode ser encontrado através do link https://www.kaggle.com/c/santander-customer-satisfaction. Esse dataset, refere-se a dados bancários de clientes do banco Santander, sendo as features anônimas. Sem mais delongas, vamos para a parte prática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para dar início ao trabalho, vamos importar as três bibliotecas a serem utilizadas e carregar os dados de treino e de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Dados de treino e teste\n",
    "treino = pd.read_csv('C:/Users/otavio/Mundo/medium/data/santander-train.csv', index_col = 0)\n",
    "teste  = pd.read_csv('C:/Users/otavio/Mundo/medium/data/santander-test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover a coluna target dos dados de treino e analisar o formato dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo coluna TARGET dos dados de treino\n",
    "treino.drop(labels = ['TARGET'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: (76020, 369)\n",
      "Dados de teste : (75818, 369)\n"
     ]
    }
   ],
   "source": [
    "# Shape dos dados de treino e teste\n",
    "print('Dados de treino:', treino.shape)\n",
    "print('Dados de teste :', teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Através do código acima, podemos observar que os datasets apresentam 369 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, vamos analisar se o conjunto de dados apresenta **features constantes**, além de determinar quantas e quais são essas features. Para isso, será aplicado o método VarianceThreshold, aplicando um threshold igual a 0, ou seja, iremos mapear aquelas features que possuem variância igual a zero através do fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vt = VarianceThreshold(threshold = 0)\n",
    "vt.fit(treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método get_support é um vetor booleano que indica quais features são retidas. Se somarmos get_support, obtemos quantas features NÃO são constantes. De todas as 369 features, 335 apresentaram variância diferente de 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vt.get_support())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com poucas linhas de código, foi possível determinar que 34 features apresentaram variância igual a 0 e criar uma lista de quais as features que serão excluídas dos datasets de treino e teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features constantes:  34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_var2_0',\n",
       " 'ind_var2',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28_0',\n",
       " 'ind_var28',\n",
       " 'ind_var27',\n",
       " 'ind_var41',\n",
       " 'ind_var46_0',\n",
       " 'ind_var46',\n",
       " 'num_var27_0',\n",
       " 'num_var28_0',\n",
       " 'num_var28',\n",
       " 'num_var27',\n",
       " 'num_var41',\n",
       " 'num_var46_0',\n",
       " 'num_var46',\n",
       " 'saldo_var28',\n",
       " 'saldo_var27',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_medio_var13_medio_hace3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features constantes\n",
    "features_constantes = [feature for feature in treino.columns if feature not in treino.columns[vt.get_support()]]\n",
    "print('Número de features constantes: ', len(features_constantes))\n",
    "features_constantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez determinada quais as features são constantes, podemos remove-las dos nossos dados utilizando o método transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as features constantes dos datasets\n",
    "treino = vt.transform(treino)\n",
    "teste  = vt.transform(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: (76020, 335)\n",
      "Dados de teste : (75818, 335)\n"
     ]
    }
   ],
   "source": [
    "# Shapes dos datasets\n",
    "print('Dados de treino:', treino.shape)\n",
    "print('Dados de teste :', teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pronto! Os dadasets de treino e de teste estão sem as features constantes. Realmente é muito simples fazer e remoção e podemos notar a grande eficácia que o método traz para a análise, reduzindo o dataset consideravelmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos focar nossa análise nas **features quase-constantes**. A metodologia empregada é a mesma que foi desenvolvida anteriormente, com uma única diferença. Dessa vez, o threshold terá o valor igual a 0,01, ou seja, queremos remover as variáveis que apresentarem inferior a este limite. Portanto, irei apenas apresentar o código, uma vez que a explicação é a mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando novamente os dados de treino e teste\n",
    "treino = pd.read_csv('C:/Users/otavio/Mundo/medium/data/santander-train.csv', index_col = 0)\n",
    "teste  = pd.read_csv('C:/Users/otavio/Mundo/medium/data/santander-test.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo coluna TARGET dos dados de treino\n",
    "treino.drop(labels = ['TARGET'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VarianceThreshold(threshold=0.01)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizando sklearn VarianceThreshold para encontrar as features quase-constantes\n",
    "vt = VarianceThreshold(threshold = 0.01) # \n",
    "vt.fit(treino) # fit encontra as features com baixa variância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_support é um vetor booleano que indica quais features são retidas\n",
    "# se somarmos get_support, obtemos quantas features NÃO são quase-constantes\n",
    "sum(vt.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features quase-constantes:  97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ind_var1',\n",
       " 'ind_var2_0',\n",
       " 'ind_var2',\n",
       " 'ind_var6_0',\n",
       " 'ind_var6',\n",
       " 'ind_var13_largo',\n",
       " 'ind_var13_medio_0',\n",
       " 'ind_var13_medio',\n",
       " 'ind_var14',\n",
       " 'ind_var17_0',\n",
       " 'ind_var17',\n",
       " 'ind_var18_0',\n",
       " 'ind_var18',\n",
       " 'ind_var19',\n",
       " 'ind_var20_0',\n",
       " 'ind_var20',\n",
       " 'ind_var27_0',\n",
       " 'ind_var28_0',\n",
       " 'ind_var28',\n",
       " 'ind_var27',\n",
       " 'ind_var29_0',\n",
       " 'ind_var29',\n",
       " 'ind_var30_0',\n",
       " 'ind_var31_0',\n",
       " 'ind_var31',\n",
       " 'ind_var32_cte',\n",
       " 'ind_var32_0',\n",
       " 'ind_var32',\n",
       " 'ind_var33_0',\n",
       " 'ind_var33',\n",
       " 'ind_var34_0',\n",
       " 'ind_var34',\n",
       " 'ind_var40',\n",
       " 'ind_var41',\n",
       " 'ind_var39',\n",
       " 'ind_var44_0',\n",
       " 'ind_var44',\n",
       " 'ind_var46_0',\n",
       " 'ind_var46',\n",
       " 'num_var6_0',\n",
       " 'num_var6',\n",
       " 'num_var13_medio_0',\n",
       " 'num_var13_medio',\n",
       " 'num_var18_0',\n",
       " 'num_var18',\n",
       " 'num_var27_0',\n",
       " 'num_var28_0',\n",
       " 'num_var28',\n",
       " 'num_var27',\n",
       " 'num_var29_0',\n",
       " 'num_var29',\n",
       " 'num_var33',\n",
       " 'num_var34_0',\n",
       " 'num_var34',\n",
       " 'num_var41',\n",
       " 'num_var46_0',\n",
       " 'num_var46',\n",
       " 'saldo_var28',\n",
       " 'saldo_var27',\n",
       " 'saldo_var41',\n",
       " 'saldo_var46',\n",
       " 'imp_amort_var18_hace3',\n",
       " 'imp_amort_var34_hace3',\n",
       " 'imp_reemb_var13_hace3',\n",
       " 'imp_reemb_var33_hace3',\n",
       " 'imp_trasp_var17_out_hace3',\n",
       " 'imp_trasp_var33_out_hace3',\n",
       " 'ind_var7_emit_ult1',\n",
       " 'ind_var7_recib_ult1',\n",
       " 'num_var2_0_ult1',\n",
       " 'num_var2_ult1',\n",
       " 'num_aport_var33_hace3',\n",
       " 'num_aport_var33_ult1',\n",
       " 'num_var7_emit_ult1',\n",
       " 'num_compra_var44_hace3',\n",
       " 'num_meses_var13_medio_ult3',\n",
       " 'num_meses_var17_ult3',\n",
       " 'num_meses_var29_ult3',\n",
       " 'num_meses_var33_ult3',\n",
       " 'num_meses_var44_ult3',\n",
       " 'num_reemb_var13_hace3',\n",
       " 'num_reemb_var13_ult1',\n",
       " 'num_reemb_var17_hace3',\n",
       " 'num_reemb_var17_ult1',\n",
       " 'num_reemb_var33_hace3',\n",
       " 'num_reemb_var33_ult1',\n",
       " 'num_trasp_var17_in_hace3',\n",
       " 'num_trasp_var17_in_ult1',\n",
       " 'num_trasp_var17_out_hace3',\n",
       " 'num_trasp_var17_out_ult1',\n",
       " 'num_trasp_var33_in_hace3',\n",
       " 'num_trasp_var33_in_ult1',\n",
       " 'num_trasp_var33_out_hace3',\n",
       " 'num_trasp_var33_out_ult1',\n",
       " 'num_venta_var44_hace3',\n",
       " 'saldo_var2_ult1',\n",
       " 'saldo_medio_var13_medio_hace3']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features quase-constantes\n",
    "features_quaseConstantes = [feature for feature in treino.columns if feature not in treino.columns[vt.get_support()]]\n",
    "print('Número de features quase-constantes: ', len(features_quaseConstantes))\n",
    "features_quaseConstantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado obtemos que 97 features podem ser consideradas como quase-constantes. Lembrando que os datasets possuem 369 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    99.623783\n",
       "1     0.376217\n",
       "Name: ind_var1, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentagem de observação mostrando cada um dos diferentes valores\n",
    "treino['ind_var1'].value_counts() / np.float(len(treino)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as features quase-constantes dos datasets\n",
    "treino = vt.transform(treino)\n",
    "teste  = vt.transform(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: (76020, 272)\n",
      "Dados de teste : (75818, 272)\n"
     ]
    }
   ],
   "source": [
    "# Shapes dos datasets\n",
    "print('Dados de treino:', treino.shape)\n",
    "print('Dados de teste :', teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui está o resultado final. Os datasets de treino e teste foram reduzidos para 272 features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, foi possível demonstrar como esse método simples pode nos auxiliar para fazer a avaliação e remoção de features constantes e quase-constantes, principalmente quando o dataset de estudo possui um número elevado de variáveis. O dataset teve a exclusão de 97 features que não seriam úteis para o desenvolvimento do algoritmo de machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A documentação oficial pode ser encontrada aqui https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outras referências legais sobre o assunto:\n",
    "- https://www.kaggle.com/prashant111/comprehensive-guide-on-feature-selection\n",
    "- https://trainindata.medium.com/feature-selection-for-machine-learning-a-comprehensive-overview-bd571db5dd2d\n",
    "- https://towardsdatascience.com/feature-selection-in-python-using-filter-method-7ae5cbc4ee05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eu sou o Otavio, estusiasta de dados, ciência e tecnologia. Se você tem alguma crítica, dúvida ou sugestão pode entrar em contato comigo através do e-mail otaviosanluz@gmail.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obrigado!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
